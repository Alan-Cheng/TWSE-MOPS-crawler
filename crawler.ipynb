{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time_seq(co_id, year):\n",
    "\n",
    "    url = 'https://mops.twse.com.tw/mops/web/t05st01'\n",
    "\n",
    "    params = {\n",
    "    'encodeURIComponent': '1',\n",
    "    'step': '1',\n",
    "    'firstin': '1',\n",
    "    'off': '1',\n",
    "    'queryName': 'co_id',\n",
    "    'inpuType': 'co_id',\n",
    "    'TYPEK': 'all',\n",
    "    'isnew': 'false',\n",
    "    'co_id': co_id,\n",
    "    'year' : year\n",
    "    }\n",
    "\n",
    "    for i in range(20):\n",
    "        try:\n",
    "            response = requests.post(url, data=params, timeout = 10)\n",
    "            response.encoding = 'utf-8'\n",
    "            html_doc = response.text\n",
    "            soup = BeautifulSoup(html_doc, 'html.parser')\n",
    "            \n",
    "            alarm = soup.find('td')\n",
    "            if('Overrun' in alarm.text):\n",
    "                now = time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "                print(\"連線被阻擋RRRRRRRRRRRRRRRRRRRRRR(\" + now + \")，兩分鐘後重新連線\")\n",
    "                time.sleep(120)\n",
    "                continue\n",
    "\n",
    "\n",
    "            table = soup.find('table', {'class': 'hasBorder'})\n",
    "            rows = table.findAll('tr')\n",
    "\n",
    "            button = soup.find('td')\n",
    "\n",
    "\n",
    "            button_value = button.find_all('input', value = \"詳細資料\")\n",
    "            break\n",
    "        \n",
    "        except TimeoutError:\n",
    "            now = time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            print(\"連線被中斷(\" + now + \")，兩分鐘後重新連線\")\n",
    "            time.sleep(120)\n",
    "            continue\n",
    "\n",
    "        except requests.exceptions.ReadTimeout:\n",
    "            now = time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            print(\"連線被中斷(\" + now + \")，兩分鐘後重新連線\")\n",
    "            time.sleep(120)\n",
    "            continue\n",
    "\n",
    "        except AttributeError:\n",
    "            return [], [], []\n",
    "        \n",
    "  \n",
    "\n",
    "    datetime_list = [] #格式範例: 110/01/01 09:00:00\n",
    "    date_list = []  #格式範例: 110/01/01\n",
    "    seq_no_list = [] #格式範例: ['1','2','3'...]\n",
    "\n",
    "    for row in rows:\n",
    "        cols = row.findAll('td')\n",
    "        if len(cols) >= 3:\n",
    "            datetime_list.append(cols[2].text.strip() + \" \" +cols[3].text.strip())\n",
    "            date_list.append(cols[2].text.strip())\n",
    "\n",
    "    for value in button_value:\n",
    "        matche = re.findall(r\"document.t05st01_fm.seq_no.value='(\\d+)\", value.get('onclick'))\n",
    "        seq_no_list.append(matche[0])\n",
    "\n",
    "\n",
    "    return datetime_list, date_list, seq_no_list\n",
    "\n",
    "# a,b,c = get_time_seq('2330', '110')\n",
    "# print((a))\n",
    "# print(b)\n",
    "# print((c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#處理時間格式的function(送入datetime，例如110/01/01 09:00:00)\n",
    "\n",
    "#回傳民國年('110')\n",
    "def get_yyy(datetime): \n",
    "    return datetime.split('/')[0]\n",
    "\n",
    "\n",
    "#回傳年月日('20210101')\n",
    "def get_yyyymmdd(datetime):\n",
    "    return str(int(datetime.split(\"/\")[0])+1911) + datetime.split(\"/\")[1] + datetime.split(\"/\")[2].split(\" \")[0]\n",
    "\n",
    "#回傳時分秒('090000')\n",
    "def get_hhmmss(datetime):\n",
    "    return datetime.split(\"/\")[2].split(\" \")[1].replace(\":\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_daily_info(co_id, month, datetime, seq_no):\n",
    "\n",
    "    yyyymmdd = get_yyyymmdd(datetime)\n",
    "    hhmmss = get_hhmmss(datetime)\n",
    "    y = get_yyy(datetime)\n",
    "\n",
    "    params = {\n",
    "    \"firstin\": \"true\",\n",
    "    \"b_date\": \"\",\n",
    "    \"e_date\": \"\",\n",
    "    \"TYPEK\": \"all\",\n",
    "    \"year\": str(y),  #格式為民國年\n",
    "    \"month\": \"all\",\n",
    "    \"type\": \"\",\n",
    "    \"co_id\": str(co_id), #公司代號\n",
    "    \"spoke_date\": str(yyyymmdd), #格式為yyyymmdd\n",
    "    \"spoke_time\": str(hhmmss), #格式為hhmmss\n",
    "    \"seq_no\": str(seq_no), #當日的重大訊息id(由1開始，每日更新)\n",
    "    \"MEETING_STEP\":\"\",\n",
    "    \"e_month\": \"all\",\n",
    "    \"step\": \"2\",\n",
    "    \"off\": \"1\",\n",
    "    \"month\" : str(month)\n",
    "    }\n",
    "\n",
    "    url = 'https://mops.twse.com.tw/mops/web/t05st01'\n",
    "\n",
    "    for i in range(30):\n",
    "        try:\n",
    "            time.sleep(random.randint(1, 3))\n",
    "            response = requests.post(url, data=params, timeout=10)\n",
    "            response.encoding = 'utf-8'\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "            alarm = soup.find('td')\n",
    "            if('Overrun' in alarm.text):\n",
    "                now = time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "                print(\"連線被阻擋RRRRRRRRRRRRRRRRRRRRRR(\" + now + \")，兩分鐘後重新連線\")\n",
    "                time.sleep(120)\n",
    "                continue\n",
    "\n",
    "            contents = soup.find_all('td', {'class': 'odd'})\n",
    "            break\n",
    "        except requests.exceptions.ReadTimeout:\n",
    "            now = time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            print(\"連線被中斷(\" + now + \")，兩分鐘後重新連線\")\n",
    "            time.sleep(120)\n",
    "            continue\n",
    "\n",
    "        except TimeoutError:\n",
    "            now = time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            print(\"連線被中斷(\" + now + \")，兩分鐘後重新連線\")\n",
    "            time.sleep(120)\n",
    "            continue\n",
    "\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    contents = soup.find_all('td', {'class': 'odd'})\n",
    "\n",
    "    header = ['序號',\n",
    "            '發言日期',\n",
    "            '發言時間',\n",
    "            '發言人',\n",
    "            '發言人職稱',\n",
    "            '發言人電話',\n",
    "            '主旨',\n",
    "            '符合條款',\n",
    "            '事實發生日',\n",
    "            '說明']\n",
    "    content_list = []\n",
    "    for content in contents:\n",
    "        content_list.append(content.text.strip().replace('\\n', ' ').replace('\\r', '').replace('\\t', '').replace('\\xa0', ''))\n",
    "\n",
    "    #將內容存為字典\n",
    "    dic = dict(zip(header, content_list))\n",
    "    \n",
    "    return dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawer(co_id, year, month):\n",
    "    print(\"開始蒐集\"+ str(co_id)+ \"公司\" +str(year)+\"年\"+str(month)+\"月的重要資訊\")\n",
    "\n",
    "    #建立要輸出的dataframe\n",
    "    df_header = ['序號',\n",
    "                '發言日期',\n",
    "                '發言時間',\n",
    "                '發言人',\n",
    "                '發言人職稱',\n",
    "                '發言人電話',\n",
    "                '主旨',\n",
    "                '符合條款',\n",
    "                '事實發生日',\n",
    "                '說明']\n",
    "\n",
    "    df = pd.DataFrame(columns=df_header)\n",
    "\n",
    "    datetime_list, date_list, seqno_list = get_time_seq(co_id, year)    \n",
    "    \n",
    "    if(datetime_list == []):\n",
    "        return df\n",
    "\n",
    "    for i in range(len(datetime_list)):\n",
    "            \n",
    "        if(datetime_list[i].split(\" \")[0].split(\"/\")[1] == month):\n",
    "            day = datetime_list[i].split(\" \")[0]\n",
    "            \n",
    "            info = output_daily_info(co_id, month, datetime_list[i], seqno_list[i])\n",
    "\n",
    "            print(\"已蒐集到\" + day + \"的第 \" + str(seqno_list[i]) + \" 序號資料( \" + time.strftime(\"%Y-%m-%d %H:%M:%S\") + \" )\")\n",
    "\n",
    "            df = pd.concat([df, pd.DataFrame(info, index=[0])], ignore_index=True)\n",
    "\n",
    "            time.sleep(random.randint(1, 3))\n",
    "\n",
    "    df['公司代號'] = co_id\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_folder(co_id, year):\n",
    "    folder = os.path.exists('C:\\\\Users\\\\user\\\\Desktop\\\\Crawler\\\\data\\\\'+ co_id )\n",
    "    if not folder:\n",
    "        os.makedirs('C:\\\\Users\\\\user\\\\Desktop\\\\Crawler\\\\data\\\\'+ co_id)\n",
    "    else:\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "開始蒐集6452公司110年01月的重要資訊\n",
      "該公司(6452)110年01月，蒐集到0筆重要資訊\n",
      "開始蒐集6452公司110年02月的重要資訊\n",
      "已蒐集到110/02/23的第 1 序號資料( 2023-03-23 23:26:12 )\n",
      "已蒐集到110/02/26的第 4 序號資料( 2023-03-23 23:26:17 )\n",
      "已蒐集到110/02/26的第 1 序號資料( 2023-03-23 23:26:20 )\n",
      "該公司(6452)110年02月，蒐集到3筆重要資訊\n",
      "開始蒐集6452公司110年03月的重要資訊\n",
      "已蒐集到110/03/08的第 1 序號資料( 2023-03-23 23:26:25 )\n",
      "已蒐集到110/03/31的第 1 序號資料( 2023-03-23 23:26:29 )\n",
      "該公司(6452)110年03月，蒐集到2筆重要資訊\n",
      "開始蒐集6452公司110年04月的重要資訊\n",
      "該公司(6452)110年04月，蒐集到0筆重要資訊\n",
      "開始蒐集6452公司110年05月的重要資訊\n",
      "已蒐集到110/05/05的第 1 序號資料( 2023-03-23 23:26:31 )\n",
      "已蒐集到110/05/05的第 3 序號資料( 2023-03-23 23:26:34 )\n",
      "已蒐集到110/05/21的第 1 序號資料( 2023-03-23 23:26:38 )\n",
      "已蒐集到110/05/27的第 1 序號資料( 2023-03-23 23:26:43 )\n",
      "該公司(6452)110年05月，蒐集到4筆重要資訊\n",
      "開始蒐集6452公司110年06月的重要資訊\n",
      "該公司(6452)110年06月，蒐集到0筆重要資訊\n",
      "開始蒐集6452公司110年07月的重要資訊\n",
      "已蒐集到110/07/01的第 1 序號資料( 2023-03-23 23:26:47 )\n",
      "已蒐集到110/07/16的第 1 序號資料( 2023-03-23 23:26:50 )\n",
      "該公司(6452)110年07月，蒐集到2筆重要資訊\n",
      "開始蒐集6452公司110年08月的重要資訊\n",
      "該公司(6452)110年08月，蒐集到0筆重要資訊\n",
      "開始蒐集6452公司110年09月的重要資訊\n",
      "該公司(6452)110年09月，蒐集到0筆重要資訊\n",
      "開始蒐集6452公司110年10月的重要資訊\n",
      "該公司(6452)110年10月，蒐集到0筆重要資訊\n",
      "開始蒐集6452公司110年11月的重要資訊\n",
      "該公司(6452)110年11月，蒐集到0筆重要資訊\n",
      "開始蒐集6452公司110年12月的重要資訊\n",
      "該公司(6452)110年12月，蒐集到0筆重要資訊\n",
      "開始蒐集6452公司111年01月的重要資訊\n",
      "連線被阻擋RRRRRRRRRRRRRRRRRRRRRR(2023-03-23 23:26:53)，兩分鐘後重新連線\n",
      "該公司(6452)111年01月，蒐集到0筆重要資訊\n",
      "開始蒐集6452公司111年02月的重要資訊\n",
      "該公司(6452)111年02月，蒐集到0筆重要資訊\n",
      "開始蒐集6452公司111年03月的重要資訊\n",
      "該公司(6452)111年03月，蒐集到0筆重要資訊\n",
      "開始蒐集6452公司111年04月的重要資訊\n",
      "該公司(6452)111年04月，蒐集到0筆重要資訊\n",
      "開始蒐集6452公司111年05月的重要資訊\n",
      "該公司(6452)111年05月，蒐集到0筆重要資訊\n",
      "開始蒐集6452公司111年06月的重要資訊\n",
      "該公司(6452)111年06月，蒐集到0筆重要資訊\n",
      "開始蒐集6452公司111年07月的重要資訊\n",
      "該公司(6452)111年07月，蒐集到0筆重要資訊\n",
      "開始蒐集6452公司111年08月的重要資訊\n",
      "該公司(6452)111年08月，蒐集到0筆重要資訊\n",
      "開始蒐集6452公司111年09月的重要資訊\n",
      "該公司(6452)111年09月，蒐集到0筆重要資訊\n",
      "開始蒐集6452公司111年10月的重要資訊\n",
      "該公司(6452)111年10月，蒐集到0筆重要資訊\n",
      "開始蒐集6452公司111年11月的重要資訊\n",
      "該公司(6452)111年11月，蒐集到0筆重要資訊\n",
      "開始蒐集6452公司111年12月的重要資訊\n",
      "該公司(6452)111年12月，蒐集到0筆重要資訊\n",
      "=============6452公司蒐集完畢==============\n",
      "開始蒐集3383公司110年01月的重要資訊\n",
      "已蒐集到110/01/04的第 3 序號資料( 2023-03-23 23:28:57 )\n",
      "已蒐集到110/01/04的第 4 序號資料( 2023-03-23 23:29:02 )\n",
      "已蒐集到110/01/07的第 1 序號資料( 2023-03-23 23:29:09 )\n",
      "已蒐集到110/01/20的第 1 序號資料( 2023-03-23 23:29:13 )\n",
      "該公司(3383)110年01月，蒐集到4筆重要資訊\n",
      "開始蒐集3383公司110年02月的重要資訊\n",
      "已蒐集到110/02/20的第 1 序號資料( 2023-03-23 23:29:16 )\n",
      "該公司(3383)110年02月，蒐集到1筆重要資訊\n",
      "開始蒐集3383公司110年03月的重要資訊\n",
      "已蒐集到110/03/19的第 1 序號資料( 2023-03-23 23:29:19 )\n",
      "已蒐集到110/03/23的第 2 序號資料( 2023-03-23 23:29:23 )\n",
      "已蒐集到110/03/26的第 1 序號資料( 2023-03-23 23:29:29 )\n",
      "已蒐集到110/03/26的第 2 序號資料( 2023-03-23 23:29:33 )\n",
      "已蒐集到110/03/26的第 3 序號資料( 2023-03-23 23:29:37 )\n",
      "已蒐集到110/03/26的第 4 序號資料( 2023-03-23 23:29:41 )\n",
      "已蒐集到110/03/26的第 5 序號資料( 2023-03-23 23:29:45 )\n",
      "已蒐集到110/03/26的第 6 序號資料( 2023-03-23 23:29:50 )\n",
      "已蒐集到110/03/26的第 1 序號資料( 2023-03-23 23:29:57 )\n",
      "該公司(3383)110年03月，蒐集到9筆重要資訊\n",
      "開始蒐集3383公司110年04月的重要資訊\n",
      "已蒐集到110/04/01的第 1 序號資料( 2023-03-23 23:30:01 )\n",
      "已蒐集到110/04/20的第 1 序號資料( 2023-03-23 23:30:04 )\n",
      "該公司(3383)110年04月，蒐集到2筆重要資訊\n",
      "開始蒐集3383公司110年05月的重要資訊\n",
      "已蒐集到110/05/06的第 2 序號資料( 2023-03-23 23:30:09 )\n",
      "已蒐集到110/05/20的第 1 序號資料( 2023-03-23 23:30:11 )\n",
      "已蒐集到110/05/21的第 1 序號資料( 2023-03-23 23:30:17 )\n",
      "該公司(3383)110年05月，蒐集到3筆重要資訊\n",
      "開始蒐集3383公司110年06月的重要資訊\n",
      "已蒐集到110/06/18的第 1 序號資料( 2023-03-23 23:30:22 )\n",
      "已蒐集到110/06/30的第 2 序號資料( 2023-03-23 23:30:28 )\n",
      "該公司(3383)110年06月，蒐集到2筆重要資訊\n",
      "開始蒐集3383公司110年07月的重要資訊\n",
      "已蒐集到110/07/20的第 1 序號資料( 2023-03-23 23:30:33 )\n",
      "已蒐集到110/07/30的第 1 序號資料( 2023-03-23 23:30:37 )\n",
      "已蒐集到110/07/30的第 2 序號資料( 2023-03-23 23:30:42 )\n",
      "該公司(3383)110年07月，蒐集到3筆重要資訊\n",
      "開始蒐集3383公司110年08月的重要資訊\n",
      "已蒐集到110/08/04的第 1 序號資料( 2023-03-23 23:30:47 )\n",
      "已蒐集到110/08/04的第 3 序號資料( 2023-03-23 23:30:50 )\n",
      "已蒐集到110/08/12的第 1 序號資料( 2023-03-23 23:30:52 )\n",
      "已蒐集到110/08/12的第 2 序號資料( 2023-03-23 23:30:55 )\n",
      "已蒐集到110/08/16的第 3 序號資料( 2023-03-23 23:30:59 )\n",
      "已蒐集到110/08/17的第 2 序號資料( 2023-03-23 23:31:05 )\n",
      "已蒐集到110/08/20的第 1 序號資料( 2023-03-23 23:31:09 )\n",
      "該公司(3383)110年08月，蒐集到7筆重要資訊\n",
      "開始蒐集3383公司110年09月的重要資訊\n",
      "已蒐集到110/09/17的第 1 序號資料( 2023-03-23 23:31:13 )\n",
      "該公司(3383)110年09月，蒐集到1筆重要資訊\n",
      "開始蒐集3383公司110年10月的重要資訊\n",
      "已蒐集到110/10/19的第 1 序號資料( 2023-03-23 23:31:17 )\n",
      "該公司(3383)110年10月，蒐集到1筆重要資訊\n",
      "開始蒐集3383公司110年11月的重要資訊\n",
      "已蒐集到110/11/12的第 3 序號資料( 2023-03-23 23:31:23 )\n",
      "已蒐集到110/11/12的第 2 序號資料( 2023-03-23 23:31:26 )\n",
      "已蒐集到110/11/19的第 1 序號資料( 2023-03-23 23:31:31 )\n",
      "該公司(3383)110年11月，蒐集到3筆重要資訊\n",
      "開始蒐集3383公司110年12月的重要資訊\n",
      "已蒐集到110/12/09的第 1 序號資料( 2023-03-23 23:31:35 )\n",
      "已蒐集到110/12/20的第 1 序號資料( 2023-03-23 23:31:41 )\n",
      "已蒐集到110/12/20的第 1 序號資料( 2023-03-23 23:31:45 )\n",
      "已蒐集到110/12/27的第 1 序號資料( 2023-03-23 23:31:48 )\n",
      "已蒐集到110/12/30的第 1 序號資料( 2023-03-23 23:31:52 )\n",
      "已蒐集到110/12/30的第 2 序號資料( 2023-03-23 23:31:57 )\n",
      "該公司(3383)110年12月，蒐集到6筆重要資訊\n",
      "開始蒐集3383公司111年01月的重要資訊\n",
      "已蒐集到111/01/07的第 1 序號資料( 2023-03-23 23:32:01 )\n",
      "已蒐集到111/01/07的第 2 序號資料( 2023-03-23 23:32:06 )\n",
      "已蒐集到111/01/19的第 2 序號資料( 2023-03-23 23:32:12 )\n",
      "該公司(3383)111年01月，蒐集到3筆重要資訊\n",
      "開始蒐集3383公司111年02月的重要資訊\n",
      "已蒐集到111/02/18的第 1 序號資料( 2023-03-23 23:32:18 )\n",
      "該公司(3383)111年02月，蒐集到1筆重要資訊\n",
      "開始蒐集3383公司111年03月的重要資訊\n",
      "已蒐集到111/03/07的第 1 序號資料( 2023-03-23 23:32:24 )\n",
      "已蒐集到111/03/15的第 1 序號資料( 2023-03-23 23:32:26 )\n",
      "已蒐集到111/03/15的第 2 序號資料( 2023-03-23 23:32:32 )\n",
      "已蒐集到111/03/15的第 3 序號資料( 2023-03-23 23:32:36 )\n",
      "已蒐集到111/03/15的第 4 序號資料( 2023-03-23 23:32:39 )\n",
      "已蒐集到111/03/15的第 5 序號資料( 2023-03-23 23:32:43 )\n",
      "已蒐集到111/03/15的第 6 序號資料( 2023-03-23 23:32:45 )\n",
      "已蒐集到111/03/15的第 7 序號資料( 2023-03-23 23:32:49 )\n",
      "已蒐集到111/03/15的第 8 序號資料( 2023-03-23 23:32:52 )\n",
      "已蒐集到111/03/15的第 9 序號資料( 2023-03-23 23:32:57 )\n",
      "該公司(3383)111年03月，蒐集到10筆重要資訊\n",
      "開始蒐集3383公司111年04月的重要資訊\n",
      "已蒐集到111/04/22的第 1 序號資料( 2023-03-23 23:33:00 )\n",
      "已蒐集到111/04/22的第 2 序號資料( 2023-03-23 23:33:03 )\n",
      "已蒐集到111/04/22的第 3 序號資料( 2023-03-23 23:33:07 )\n",
      "已蒐集到111/04/22的第 4 序號資料( 2023-03-23 23:33:10 )\n",
      "已蒐集到111/04/25的第 1 序號資料( 2023-03-23 23:33:14 )\n",
      "已蒐集到111/04/29的第 1 序號資料( 2023-03-23 23:33:20 )\n",
      "該公司(3383)111年04月，蒐集到6筆重要資訊\n",
      "開始蒐集3383公司111年05月的重要資訊\n",
      "已蒐集到111/05/12的第 1 序號資料( 2023-03-23 23:33:25 )\n",
      "已蒐集到111/05/12的第 2 序號資料( 2023-03-23 23:33:30 )\n",
      "已蒐集到111/05/12的第 3 序號資料( 2023-03-23 23:33:34 )\n",
      "該公司(3383)111年05月，蒐集到3筆重要資訊\n",
      "開始蒐集3383公司111年06月的重要資訊\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-1c661bf093d8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0myear\u001b[0m \u001b[1;32min\u001b[0m \u001b[0myear_list\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mmonth\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmonth_list\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m                     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcrawer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mco_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myear\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmonth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"該公司(\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mco_id\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\")\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0myear\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"年\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmonth\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"月，蒐集到\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"筆重要資訊\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m                     \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-19-fe6a95c8fbb8>\u001b[0m in \u001b[0;36mcrawer\u001b[1;34m(co_id, year, month)\u001b[0m\n\u001b[0;32m     26\u001b[0m             \u001b[0mday\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdatetime_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\" \"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m             \u001b[0minfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutput_daily_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mco_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmonth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdatetime_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseqno_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"已蒐集到\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mday\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"的第 \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseqno_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\" 序號資料( \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%Y-%m-%d %H:%M:%S\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\" )\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-18-e0605b3f72a4>\u001b[0m in \u001b[0;36moutput_daily_info\u001b[1;34m(co_id, month, datetime, seq_no)\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m             \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m             \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpost\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m             \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#主程式\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    month_list = ['01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12']   #月份\n",
    "    co_id_list = ['6452', '3383', '1218', '2330', '2454', '2912', '1712', '1234', '2891', '2633'] #公司代號\n",
    "    year_list = ['110','111'] #年度\n",
    "\n",
    "    for co_id in co_id_list:\n",
    "        for year in year_list:\n",
    "            for month in month_list:\n",
    "                    df = crawer(co_id, year, month)\n",
    "                    print(\"該公司(\" + co_id + \")\" + year + \"年\" + month + \"月，蒐集到\" + str(len(df)) + \"筆重要資訊\")\n",
    "                    if(df.empty == False):\n",
    "                        new_folder(co_id, year)\n",
    "                        df.to_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Crawler\\\\data\\\\'+ co_id +\"\\\\\" + co_id +\"-\"+ year + month + '.csv', encoding='utf-8-sig')\n",
    "        print(\"=============\"+str(co_id)+\"公司蒐集完畢==============\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
